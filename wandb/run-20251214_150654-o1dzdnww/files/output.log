==========
Args:Namespace(AF_weight=1.0, MODEL='50x', absolute_delta=True, absolute_feat=False, aux_weight=4.5, batch_size=128, blur=False, config_file='config/base.yml', data_dir='/DATA2025/cjh/AAAI2025-LReID-DASK/PRID', dropout=0.5, epochs=60, epochs0=80, eval_epoch=100, evaluate=False, fix_EMA=0.5, global_alpha=100, groups=1, height=256, joint_test=False, l2sp_weight=0.01, logs_dir='/DATA2025/cjh/AAAI2025-LReID-DASK/output', lr=0.008, middle_test=False, milestones=[30], mobile=True, momentum=0.9, n_kernel=1, num_instances=4, optimizer='SGD', print_freq=200, random_rehearser=False, resume='', save_evaluation=False, seed=0, setting=1, test_folder=None, trans=True, warmup_step=10, weight_decay=0.0001, width=128, workers=8)
==========
+---------------------------+--------+------------+---------+
|            set            | images | identities | cameras |
+---------------------------+--------+------------+---------+
| IncrementalSamples4market |        |            |         |
|           train           | 12936  |    751     |    6    |
|           query           |  3368  |    750     |    6    |
|          gallery          | 15913  |    751     |    6    |
+---------------------------+--------+------------+---------+
+--------------------------------+--------+------------+---------+
|              set               | images | identities | cameras |
+--------------------------------+--------+------------+---------+
| IncrementalSamples4subcuhksysu |        |            |         |
|             train              |  4374  |    942     |    1    |
|             query              |  2900  |    2900    |    1    |
|            gallery             |  5447  |    2900    |    1    |
+--------------------------------+--------+------------+---------+
+-------------------------+--------+------------+---------+
|           set           | images | identities | cameras |
+-------------------------+--------+------------+---------+
| IncrementalSamples4duke |        |            |         |
|          train          | 16522  |    702     |    8    |
|          query          |  2228  |    702     |    8    |
|         gallery         | 17661  |    1110    |    8    |
+-------------------------+--------+------------+---------+
/DATA2025/cjh/envs/IRL/lib/python3.8/site-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
+---------------------------+--------+------------+---------+
|            set            | images | identities | cameras |
+---------------------------+--------+------------+---------+
| IncrementalSamples4msmt17 |        |            |         |
|           train           | 30248  |    1041    |    15   |
|           query           | 11659  |    3060    |    15   |
|          gallery          | 82161  |    3060    |    15   |
+---------------------------+--------+------------+---------+
Checking preprocess conditions...
imgs_labeled_dir exists: True
imgs_detected_dir exists: True
+---------------------------+--------+------------+---------+
|            set            | images | identities | cameras |
+---------------------------+--------+------------+---------+
| IncrementalSamples4cuhk03 |        |            |         |
|           train           |  7368  |    767     |    2    |
|           query           |  1400  |    700     |    2    |
|          gallery          |  5328  |    700     |    2    |
+---------------------------+--------+------------+---------+
/DATA2025/cjh/AAAI2025-LReID-DASK/PRID/SenseReID/test_gallery
+------------------------------+--------+------------+---------+
|             set              | images | identities | cameras |
+------------------------------+--------+------------+---------+
| IncrementalSamples4sensereid |        |            |         |
|            train             |  4428  |    1718    |    2    |
|            query             |  1040  |    521     |    2    |
|           gallery            |  3388  |    1718    |    2    |
+------------------------------+--------+------------+---------+
+-------------------------+--------+------------+---------+
|           set           | images | identities | cameras |
+-------------------------+--------+------------+---------+
| IncrementalSamples4grid |        |            |         |
|          train          |  250   |    125     |    6    |
|          query          |  125   |    125     |    5    |
|         gallery         |  900   |    126     |    5    |
+-------------------------+--------+------------+---------+
+-------------------------+--------+------------+---------+
|           set           | images | identities | cameras |
+-------------------------+--------+------------+---------+
| IncrementalSamples4prid |        |            |         |
|          train          |  200   |    100     |    2    |
|          query          |  100   |    100     |    1    |
|         gallery         |  649   |    649     |    1    |
+-------------------------+--------+------------+---------+
using resnet50 as a backbone
===========building ResNet===========
param fc.weight in pre-trained model does not exist in this model.base
param fc.bias in pre-trained model does not exist in this model.base
/DATA2025/cjh/envs/IRL/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/DATA2025/cjh/envs/IRL/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
using soft triplet loss for training
####### starting training on market1501 #######
Epoch: [0][71/71]	Time 0.531 (0.876)	Loss_ce 6.209 (6.209)	Loss_tp 3.328 (4.110)	
Epoch: [1][71/71]	Time 0.535 (0.636)	Loss_ce 5.933 (6.071)	Loss_tp 1.752 (2.272)	
Epoch: [2][71/71]	Time 0.532 (0.632)	Loss_ce 4.964 (5.453)	Loss_tp 0.955 (1.202)	
Epoch: [3][71/71]	Time 0.534 (0.647)	Loss_ce 3.472 (4.062)	Loss_tp 0.870 (0.850)	
Epoch: [4][71/71]	Time 0.533 (0.640)	Loss_ce 2.009 (2.572)	Loss_tp 0.595 (0.718)	
Epoch: [5][71/71]	Time 0.535 (0.636)	Loss_ce 1.128 (1.529)	Loss_tp 0.551 (0.631)	
Epoch: [6][71/71]	Time 0.540 (0.637)	Loss_ce 0.696 (0.910)	Loss_tp 0.445 (0.520)	
Epoch: [7][71/71]	Time 0.533 (0.637)	Loss_ce 0.438 (0.619)	Loss_tp 0.446 (0.470)	
Epoch: [8][71/71]	Time 0.536 (0.640)	Loss_ce 0.371 (0.445)	Loss_tp 0.356 (0.410)	
Epoch: [9][71/71]	Time 0.537 (0.636)	Loss_ce 0.488 (0.377)	Loss_tp 0.477 (0.390)	
Epoch: [10][71/71]	Time 0.537 (0.635)	Loss_ce 0.345 (0.300)	Loss_tp 0.561 (0.356)	
Epoch: [11][71/71]	Time 0.533 (0.642)	Loss_ce 0.169 (0.261)	Loss_tp 0.196 (0.325)	
Epoch: [12][71/71]	Time 0.538 (0.635)	Loss_ce 0.307 (0.217)	Loss_tp 0.446 (0.296)	
Epoch: [13][71/71]	Time 0.536 (0.632)	Loss_ce 0.169 (0.191)	Loss_tp 0.275 (0.286)	
Epoch: [14][71/71]	Time 0.540 (0.628)	Loss_ce 0.148 (0.172)	Loss_tp 0.229 (0.250)	
Epoch: [15][71/71]	Time 0.534 (0.637)	Loss_ce 0.114 (0.166)	Loss_tp 0.124 (0.239)	
Epoch: [16][71/71]	Time 0.536 (0.641)	Loss_ce 0.167 (0.134)	Loss_tp 0.220 (0.208)	
Epoch: [17][71/71]	Time 0.541 (0.632)	Loss_ce 0.085 (0.128)	Loss_tp 0.254 (0.205)	
Epoch: [18][71/71]	Time 0.537 (0.644)	Loss_ce 0.165 (0.119)	Loss_tp 0.324 (0.190)	
Epoch: [19][71/71]	Time 0.535 (0.628)	Loss_ce 0.161 (0.113)	Loss_tp 0.209 (0.188)	
Epoch: [20][71/71]	Time 0.537 (0.642)	Loss_ce 0.049 (0.103)	Loss_tp 0.127 (0.174)	
Epoch: [21][71/71]	Time 0.533 (0.646)	Loss_ce 0.101 (0.093)	Loss_tp 0.201 (0.159)	
Epoch: [22][71/71]	Time 0.535 (0.626)	Loss_ce 0.103 (0.090)	Loss_tp 0.253 (0.155)	
Epoch: [23][71/71]	Time 0.537 (0.642)	Loss_ce 0.127 (0.076)	Loss_tp 0.198 (0.125)	
Epoch: [24][71/71]	Time 0.536 (0.642)	Loss_ce 0.108 (0.081)	Loss_tp 0.157 (0.130)	
Epoch: [25][71/71]	Time 0.534 (0.642)	Loss_ce 0.139 (0.075)	Loss_tp 0.141 (0.129)	
Epoch: [26][71/71]	Time 0.533 (0.641)	Loss_ce 0.045 (0.074)	Loss_tp 0.074 (0.113)	
Epoch: [27][71/71]	Time 0.538 (0.627)	Loss_ce 0.077 (0.069)	Loss_tp 0.135 (0.112)	
Epoch: [28][71/71]	Time 0.534 (0.638)	Loss_ce 0.099 (0.064)	Loss_tp 0.122 (0.110)	
Epoch: [29][71/71]	Time 0.535 (0.646)	Loss_ce 0.039 (0.060)	Loss_tp 0.058 (0.102)	
Epoch: [30][71/71]	Time 0.536 (0.636)	Loss_ce 0.038 (0.053)	Loss_tp 0.064 (0.094)	
Epoch: [31][71/71]	Time 0.535 (0.643)	Loss_ce 0.053 (0.046)	Loss_tp 0.099 (0.083)	
Epoch: [32][71/71]	Time 0.539 (0.644)	Loss_ce 0.017 (0.042)	Loss_tp 0.022 (0.074)	
Traceback (most recent call last):
  File "continual_train.py", line 420, in <module>
    main()
  File "continual_train.py", line 50, in main
    main_worker(args, cfg)
  File "continual_train.py", line 170, in main_worker
    model = train_dataset(cfg, args, all_train_sets, all_test_only_sets, set_index, model, out_channel,
  File "continual_train.py", line 298, in train_dataset
    trainer.train(epoch, train_loader,  optimizer, training_phase=set_index + 1,
  File "/DATA2025/cjh/AAAI2025-LReID-DASK/reid/trainer.py", line 106, in train
    s_features, bn_feat, cls_outputs, feat_final_layer = self.model(s_inputs)
  File "/DATA2025/cjh/envs/IRL/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/DATA2025/cjh/envs/IRL/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 171, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/DATA2025/cjh/envs/IRL/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 181, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/DATA2025/cjh/envs/IRL/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py", line 81, in parallel_apply
    thread.join()
  File "/DATA2025/cjh/envs/IRL/lib/python3.8/threading.py", line 1011, in join
    self._wait_for_tstate_lock()
  File "/DATA2025/cjh/envs/IRL/lib/python3.8/threading.py", line 1027, in _wait_for_tstate_lock
    elif lock.acquire(block, timeout):
KeyboardInterrupt