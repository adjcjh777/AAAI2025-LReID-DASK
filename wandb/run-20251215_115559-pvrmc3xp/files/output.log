/DATA2025/cjh/envs/IRL/lib/python3.8/site-packages/torchvision/transforms/transforms.py:329: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.
  warnings.warn(
==========
Args:Namespace(AF_weight=1.0, MODEL='50x', absolute_delta=True, absolute_feat=False, aux_weight=4.5, batch_size=64, blur=False, config_file='config/base.yml', data_dir='/DATA2025/cjh/AAAI2025-LReID-DASK/PRID', dropout=0.5, epochs=60, epochs0=80, eval_epoch=100, evaluate=False, fisher_freeze=True, fisher_ratio=0.5, fisher_sample_num=1000, fix_EMA=0.5, global_alpha=100, groups=1, height=256, joint_test=False, l2sp_weight=0.01, logs_dir='/DATA2025/cjh/AAAI2025-LReID-DASK/output', lr=0.008, middle_test=True, milestones=[30], mobile=True, momentum=0.9, n_kernel=1, num_instances=4, optimizer='SGD', print_freq=200, random_rehearser=False, resume='', save_evaluation=False, seed=0, setting=3, test_folder=None, trans=True, warmup_step=10, weight_decay=0.0001, width=128, workers=8)
==========
+---------------------------+--------+------------+---------+
|            set            | images | identities | cameras |
+---------------------------+--------+------------+---------+
| IncrementalSamples4msmt17 |        |            |         |
|           train           | 30248  |    1041    |    15   |
|           query           | 11659  |    3060    |    15   |
|          gallery          | 82161  |    3060    |    15   |
+---------------------------+--------+------------+---------+
Checking preprocess conditions...
imgs_labeled_dir exists: True
imgs_detected_dir exists: True
+---------------------------+--------+------------+---------+
|            set            | images | identities | cameras |
+---------------------------+--------+------------+---------+
| IncrementalSamples4cuhk03 |        |            |         |
|           train           |  7368  |    767     |    2    |
|           query           |  1400  |    700     |    2    |
|          gallery          |  5328  |    700     |    2    |
+---------------------------+--------+------------+---------+
+--------------------------------+--------+------------+---------+
|              set               | images | identities | cameras |
+--------------------------------+--------+------------+---------+
| IncrementalSamples4subcuhksysu |        |            |         |
|             train              |  4374  |    942     |    1    |
|             query              |  2900  |    2900    |    1    |
|            gallery             |  5447  |    2900    |    1    |
+--------------------------------+--------+------------+---------+
+---------------------------+--------+------------+---------+
|            set            | images | identities | cameras |
+---------------------------+--------+------------+---------+
| IncrementalSamples4market |        |            |         |
|           train           | 12936  |    751     |    6    |
|           query           |  3368  |    750     |    6    |
|          gallery          | 15913  |    751     |    6    |
+---------------------------+--------+------------+---------+
+-------------------------+--------+------------+---------+
|           set           | images | identities | cameras |
+-------------------------+--------+------------+---------+
| IncrementalSamples4duke |        |            |         |
|          train          | 16522  |    702     |    8    |
|          query          |  2228  |    702     |    8    |
|         gallery         | 17661  |    1110    |    8    |
+-------------------------+--------+------------+---------+
/DATA2025/cjh/AAAI2025-LReID-DASK/PRID/SenseReID/test_gallery
+------------------------------+--------+------------+---------+
|             set              | images | identities | cameras |
+------------------------------+--------+------------+---------+
| IncrementalSamples4sensereid |        |            |         |
|            train             |  4428  |    1718    |    2    |
|            query             |  1040  |    521     |    2    |
|           gallery            |  3388  |    1718    |    2    |
+------------------------------+--------+------------+---------+
+-------------------------+--------+------------+---------+
|           set           | images | identities | cameras |
+-------------------------+--------+------------+---------+
| IncrementalSamples4grid |        |            |         |
|          train          |  250   |    125     |    6    |
|          query          |  125   |    125     |    5    |
|         gallery         |  900   |    126     |    5    |
+-------------------------+--------+------------+---------+
+-------------------------+--------+------------+---------+
|           set           | images | identities | cameras |
+-------------------------+--------+------------+---------+
| IncrementalSamples4prid |        |            |         |
|          train          |  200   |    100     |    2    |
|          query          |  100   |    100     |    1    |
|         gallery         |  649   |    649     |    1    |
+-------------------------+--------+------------+---------+
using resnet50 as a backbone
===========building ResNet===========
param fc.weight in pre-trained model does not exist in this model.base
param fc.bias in pre-trained model does not exist in this model.base
/DATA2025/cjh/envs/IRL/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/DATA2025/cjh/envs/IRL/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
using soft triplet loss for training
####### starting training on msmt17 #######
Epoch: [0][206/206]	Time 0.177 (0.282)	Loss_ce 6.167 (6.196)	Loss_tp 2.737 (3.499)	
Epoch: [1][206/206]	Time 0.178 (0.239)	Loss_ce 5.618 (5.894)	Loss_tp 0.978 (1.532)	
Epoch: [2][206/206]	Time 0.170 (0.234)	Loss_ce 3.569 (4.515)	Loss_tp 0.765 (0.841)	
Epoch: [3][206/206]	Time 0.178 (0.231)	Loss_ce 2.387 (2.689)	Loss_tp 0.805 (0.758)	
Epoch: [4][206/206]	Time 0.191 (0.246)	Loss_ce 1.183 (1.461)	Loss_tp 0.697 (0.692)	
Epoch: [5][206/206]	Time 0.183 (0.303)	Loss_ce 0.955 (0.871)	Loss_tp 0.787 (0.628)	
Epoch: [6][206/206]	Time 0.229 (0.299)	Loss_ce 0.457 (0.630)	Loss_tp 0.559 (0.577)	
Epoch: [7][206/206]	Time 0.171 (0.296)	Loss_ce 0.480 (0.523)	Loss_tp 0.585 (0.495)	
Epoch: [8][206/206]	Time 0.191 (0.256)	Loss_ce 0.488 (0.464)	Loss_tp 0.406 (0.464)	
Epoch: [9][206/206]	Time 0.160 (0.265)	Loss_ce 0.276 (0.392)	Loss_tp 0.339 (0.415)	
Epoch: [10][206/206]	Time 0.214 (0.260)	Loss_ce 0.373 (0.368)	Loss_tp 0.456 (0.413)	
Epoch: [11][206/206]	Time 0.193 (0.260)	Loss_ce 0.364 (0.347)	Loss_tp 0.358 (0.413)	
Epoch: [12][206/206]	Time 0.192 (0.257)	Loss_ce 0.289 (0.283)	Loss_tp 0.492 (0.351)	
Epoch: [13][206/206]	Time 0.185 (0.255)	Loss_ce 0.428 (0.247)	Loss_tp 0.455 (0.320)	
Epoch: [14][206/206]	Time 0.213 (0.293)	Loss_ce 0.236 (0.262)	Loss_tp 0.420 (0.356)	
Epoch: [15][206/206]	Time 0.225 (0.300)	Loss_ce 0.139 (0.254)	Loss_tp 0.347 (0.342)	
Epoch: [16][206/206]	Time 0.173 (0.301)	Loss_ce 0.433 (0.300)	Loss_tp 0.733 (0.394)	
Epoch: [17][206/206]	Time 0.202 (0.293)	Loss_ce 0.212 (0.294)	Loss_tp 0.298 (0.397)	
Epoch: [18][206/206]	Time 0.179 (0.298)	Loss_ce 0.308 (0.284)	Loss_tp 0.273 (0.407)	
Epoch: [19][206/206]	Time 0.185 (0.287)	Loss_ce 0.235 (0.236)	Loss_tp 0.367 (0.351)	
Epoch: [20][206/206]	Time 0.177 (0.256)	Loss_ce 0.564 (0.289)	Loss_tp 0.414 (0.416)	
Epoch: [21][206/206]	Time 0.178 (0.230)	Loss_ce 0.208 (0.235)	Loss_tp 0.098 (0.353)	
Epoch: [22][206/206]	Time 0.182 (0.230)	Loss_ce 0.075 (0.215)	Loss_tp 0.228 (0.321)	
Epoch: [23][206/206]	Time 0.225 (0.242)	Loss_ce 0.060 (0.195)	Loss_tp 0.169 (0.305)	
Epoch: [24][206/206]	Time 0.663 (0.287)	Loss_ce 0.361 (0.193)	Loss_tp 0.437 (0.284)	
Epoch: [25][206/206]	Time 0.211 (0.284)	Loss_ce 0.415 (0.188)	Loss_tp 0.267 (0.281)	
Epoch: [26][206/206]	Time 0.180 (0.291)	Loss_ce 0.149 (0.218)	Loss_tp 0.145 (0.326)	
Epoch: [27][206/206]	Time 0.237 (0.286)	Loss_ce 0.235 (0.188)	Loss_tp 0.591 (0.304)	
Epoch: [28][206/206]	Time 0.183 (0.289)	Loss_ce 0.115 (0.163)	Loss_tp 0.183 (0.266)	
Epoch: [29][206/206]	Time 0.175 (0.271)	Loss_ce 0.085 (0.144)	Loss_tp 0.096 (0.226)	
Epoch: [30][206/206]	Time 0.184 (0.232)	Loss_ce 0.088 (0.101)	Loss_tp 0.077 (0.171)	
Epoch: [31][206/206]	Time 0.162 (0.231)	Loss_ce 0.107 (0.082)	Loss_tp 0.238 (0.140)	
Epoch: [32][206/206]	Time 0.202 (0.234)	Loss_ce 0.163 (0.071)	Loss_tp 0.300 (0.136)	
Epoch: [33][206/206]	Time 0.195 (0.233)	Loss_ce 0.011 (0.070)	Loss_tp 0.061 (0.128)	
Epoch: [34][206/206]	Time 0.180 (0.232)	Loss_ce 0.104 (0.069)	Loss_tp 0.048 (0.126)	
Epoch: [35][206/206]	Time 0.184 (0.234)	Loss_ce 0.010 (0.062)	Loss_tp 0.082 (0.105)	
Epoch: [36][206/206]	Time 0.179 (0.234)	Loss_ce 0.013 (0.058)	Loss_tp 0.040 (0.107)	
Epoch: [37][206/206]	Time 0.196 (0.236)	Loss_ce 0.060 (0.058)	Loss_tp 0.153 (0.107)	
Epoch: [38][206/206]	Time 0.187 (0.233)	Loss_ce 0.029 (0.051)	Loss_tp 0.036 (0.094)	
Epoch: [39][206/206]	Time 0.189 (0.235)	Loss_ce 0.036 (0.053)	Loss_tp 0.061 (0.095)	
Epoch: [40][206/206]	Time 0.171 (0.264)	Loss_ce 0.027 (0.057)	Loss_tp 0.105 (0.095)	
Epoch: [41][206/206]	Time 0.188 (0.290)	Loss_ce 0.037 (0.052)	Loss_tp 0.138 (0.094)	
Epoch: [42][206/206]	Time 0.223 (0.291)	Loss_ce 0.019 (0.049)	Loss_tp 0.065 (0.090)	
Epoch: [43][206/206]	Time 0.192 (0.290)	Loss_ce 0.103 (0.050)	Loss_tp 0.088 (0.093)	
Epoch: [44][206/206]	Time 0.183 (0.291)	Loss_ce 0.015 (0.049)	Loss_tp 0.015 (0.080)	
Epoch: [45][206/206]	Time 0.207 (0.290)	Loss_ce 0.028 (0.042)	Loss_tp 0.054 (0.080)	
Epoch: [46][206/206]	Time 0.186 (0.247)	Loss_ce 0.025 (0.044)	Loss_tp 0.057 (0.083)	
Epoch: [47][206/206]	Time 0.188 (0.232)	Loss_ce 0.030 (0.038)	Loss_tp 0.083 (0.077)	
Epoch: [48][206/206]	Time 0.178 (0.231)	Loss_ce 0.005 (0.042)	Loss_tp 0.056 (0.078)	
Epoch: [49][206/206]	Time 0.192 (0.232)	Loss_ce 0.065 (0.043)	Loss_tp 0.151 (0.076)	
Epoch: [50][206/206]	Time 0.181 (0.231)	Loss_ce 0.014 (0.043)	Loss_tp 0.098 (0.077)	
Epoch: [51][206/206]	Time 0.194 (0.230)	Loss_ce 0.092 (0.042)	Loss_tp 0.152 (0.076)	
Epoch: [52][206/206]	Time 0.186 (0.232)	Loss_ce 0.009 (0.044)	Loss_tp 0.028 (0.072)	
Epoch: [53][206/206]	Time 0.191 (0.233)	Loss_ce 0.027 (0.041)	Loss_tp 0.037 (0.066)	
Epoch: [54][206/206]	Time 0.206 (0.230)	Loss_ce 0.021 (0.039)	Loss_tp 0.039 (0.065)	
Epoch: [55][206/206]	Time 0.186 (0.231)	Loss_ce 0.032 (0.042)	Loss_tp 0.088 (0.072)	
Epoch: [56][206/206]	Time 0.172 (0.232)	Loss_ce 0.012 (0.038)	Loss_tp 0.047 (0.064)	
Epoch: [57][206/206]	Time 0.182 (0.229)	Loss_ce 0.049 (0.043)	Loss_tp 0.212 (0.067)	
Epoch: [58][206/206]	Time 0.192 (0.233)	Loss_ce 0.013 (0.038)	Loss_tp 0.012 (0.071)	
Epoch: [59][206/206]	Time 0.171 (0.234)	Loss_ce 0.023 (0.038)	Loss_tp 0.029 (0.069)	
Epoch: [60][206/206]	Time 0.175 (0.233)	Loss_ce 0.006 (0.040)	Loss_tp 0.047 (0.065)	
Epoch: [61][206/206]	Time 0.180 (0.234)	Loss_ce 0.005 (0.038)	Loss_tp 0.004 (0.062)	
Epoch: [62][206/206]	Time 0.192 (0.233)	Loss_ce 0.027 (0.039)	Loss_tp 0.040 (0.060)	
Epoch: [63][206/206]	Time 0.188 (0.233)	Loss_ce 0.004 (0.038)	Loss_tp 0.031 (0.062)	
Epoch: [64][206/206]	Time 0.185 (0.234)	Loss_ce 0.036 (0.039)	Loss_tp 0.049 (0.061)	
Epoch: [65][206/206]	Time 0.179 (0.236)	Loss_ce 0.005 (0.033)	Loss_tp 0.019 (0.064)	
Epoch: [66][206/206]	Time 0.184 (0.233)	Loss_ce 0.012 (0.033)	Loss_tp 0.034 (0.062)	
Epoch: [67][206/206]	Time 0.188 (0.235)	Loss_ce 0.066 (0.037)	Loss_tp 0.090 (0.064)	
Epoch: [68][206/206]	Time 0.185 (0.236)	Loss_ce 0.092 (0.033)	Loss_tp 0.077 (0.061)	
Epoch: [69][206/206]	Time 0.187 (0.233)	Loss_ce 0.150 (0.035)	Loss_tp 0.263 (0.057)	
Epoch: [70][206/206]	Time 0.188 (0.234)	Loss_ce 0.063 (0.032)	Loss_tp 0.023 (0.056)	
Epoch: [71][206/206]	Time 0.185 (0.235)	Loss_ce 0.012 (0.030)	Loss_tp 0.085 (0.057)	
Epoch: [72][206/206]	Time 0.190 (0.231)	Loss_ce 0.018 (0.030)	Loss_tp 0.020 (0.053)	
Epoch: [73][206/206]	Time 0.189 (0.234)	Loss_ce 0.051 (0.033)	Loss_tp 0.128 (0.058)	
Epoch: [74][206/206]	Time 0.196 (0.234)	Loss_ce 0.019 (0.034)	Loss_tp 0.081 (0.056)	
Epoch: [75][206/206]	Time 0.183 (0.234)	Loss_ce 0.006 (0.031)	Loss_tp 0.031 (0.058)	
Epoch: [76][206/206]	Time 0.186 (0.231)	Loss_ce 0.018 (0.036)	Loss_tp 0.019 (0.052)	
Epoch: [77][206/206]	Time 0.182 (0.233)	Loss_ce 0.042 (0.031)	Loss_tp 0.243 (0.051)	
Epoch: [78][206/206]	Time 0.179 (0.234)	Loss_ce 0.083 (0.030)	Loss_tp 0.029 (0.054)	
Epoch: [79][206/206]	Time 0.190 (0.234)	Loss_ce 0.004 (0.030)	Loss_tp 0.020 (0.051)	
=> saved checkpoint '/DATA2025/cjh/AAAI2025-LReID-DASK/output/msmt17_checkpoint.pth.tar'
****** start perform fast testing! ******
2025-12-15 13:06:34  msmt17 feature start
2025-12-15 13:14:07  msmt17 feature done
fast testing!!!
mAP/Rank1:	35.8/62.0
2025-12-15 13:16:11  sense feature start
2025-12-15 13:16:17  sense feature done
fast testing!!!
mAP/Rank1:	35.1/27.5
2025-12-15 13:16:17  grid feature start
2025-12-15 13:16:20  grid feature done
fast testing!!!
mAP/Rank1:	12.8/8.0
2025-12-15 13:16:20  prid feature start
2025-12-15 13:16:22  prid feature done
fast testing!!!
mAP/Rank1:	23.5/16.0
Average mAP on Seen dataset: 35.8
Average R1 on Seen dataset: 62.0
msmt17		|Average	|
|35.8/62.0	|35.8/62.0	|
Average mAP on UnSeen dataset: 23.8
Average R1 on UnSeen dataset: 17.2
sense	grid	prid	|Average	|
|35.1/27.5	|12.8/8.0	|23.5/16.0	|23.8/17.2	|
35.8	62.0	23.8	17.2
=> saved checkpoint '/DATA2025/cjh/AAAI2025-LReID-DASK/output/msmt17_checkpoint.pth.tar'
Computing Fisher Information Matrix...
Fisher Matrix Computed on 1024 samples.
Param count for AKPNet's initialized parameters: 1105348
=> Loaded checkpoint 'rehearser_pretrain_learn_kernel_c1-g1_mobilenet-v3/msmt17_rehearser_49.pth.tar'
/DATA2025/cjh/envs/IRL/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/DATA2025/cjh/envs/IRL/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Applying Fisher-based Freezing (EWC-style)...
Fisher Threshold: 8.664240115294208e-13 (Top 50.0%)
Gradient mask prepared. Approx 12268064 parameters frozen.
using soft triplet loss for training
####### starting training on cuhk03 #######
Epoch: [0][76/76]	Time 0.590 (0.636)	Loss_ce 7.576 (8.219)	Loss_tp 1.040 (1.176)	
Epoch: [1][76/76]	Time 0.624 (0.642)	Loss_ce 2.222 (4.684)	Loss_tp 0.542 (0.809)	
Epoch: [2][76/76]	Time 0.580 (0.643)	Loss_ce 0.398 (1.370)	Loss_tp 0.252 (0.538)	
Epoch: [3][76/76]	Time 0.596 (0.644)	Loss_ce 0.255 (0.537)	Loss_tp 0.339 (0.385)	
Epoch: [4][76/76]	Time 0.652 (0.649)	Loss_ce 0.121 (0.330)	Loss_tp 0.126 (0.327)	
Epoch: [5][76/76]	Time 0.595 (0.655)	Loss_ce 0.025 (0.252)	Loss_tp 0.066 (0.276)	
Epoch: [6][76/76]	Time 0.593 (0.648)	Loss_ce 0.056 (0.196)	Loss_tp 0.144 (0.249)	
Epoch: [7][76/76]	Time 0.598 (0.654)	Loss_ce 0.117 (0.163)	Loss_tp 0.125 (0.204)	
Epoch: [8][76/76]	Time 0.583 (0.650)	Loss_ce 0.041 (0.127)	Loss_tp 0.320 (0.194)	
Epoch: [9][76/76]	Time 0.573 (0.656)	Loss_ce 0.066 (0.133)	Loss_tp 0.058 (0.179)	
Epoch: [10][76/76]	Time 0.597 (0.650)	Loss_ce 0.021 (0.121)	Loss_tp 0.123 (0.184)	
Epoch: [11][76/76]	Time 0.586 (0.649)	Loss_ce 0.026 (0.139)	Loss_tp 0.167 (0.206)	
Epoch: [12][76/76]	Time 0.589 (0.646)	Loss_ce 0.145 (0.154)	Loss_tp 0.137 (0.180)	
Epoch: [13][76/76]	Time 0.590 (0.648)	Loss_ce 0.025 (0.145)	Loss_tp 0.105 (0.181)	
Epoch: [14][76/76]	Time 0.588 (0.646)	Loss_ce 0.022 (0.156)	Loss_tp 0.062 (0.187)	
Epoch: [15][76/76]	Time 0.573 (0.650)	Loss_ce 0.008 (0.094)	Loss_tp 0.110 (0.154)	
Epoch: [16][76/76]	Time 0.582 (0.634)	Loss_ce 0.005 (0.093)	Loss_tp 0.069 (0.154)	
Epoch: [17][76/76]	Time 0.627 (0.655)	Loss_ce 0.303 (0.083)	Loss_tp 0.040 (0.164)	
Epoch: [18][76/76]	Time 0.584 (0.649)	Loss_ce 0.005 (0.079)	Loss_tp 0.133 (0.141)	
Epoch: [19][76/76]	Time 0.613 (0.645)	Loss_ce 0.010 (0.102)	Loss_tp 0.056 (0.133)	
Epoch: [20][76/76]	Time 0.606 (0.646)	Loss_ce 0.006 (0.089)	Loss_tp 0.055 (0.152)	
Epoch: [21][76/76]	Time 0.582 (0.646)	Loss_ce 0.013 (0.074)	Loss_tp 0.028 (0.144)	
Epoch: [22][76/76]	Time 0.587 (0.642)	Loss_ce 0.032 (0.091)	Loss_tp 0.084 (0.154)	
Epoch: [23][76/76]	Time 0.589 (0.649)	Loss_ce 0.003 (0.085)	Loss_tp 0.089 (0.155)	
Epoch: [24][76/76]	Time 0.603 (0.653)	Loss_ce 0.018 (0.082)	Loss_tp 0.020 (0.160)	
Epoch: [25][76/76]	Time 0.582 (0.646)	Loss_ce 0.004 (0.062)	Loss_tp 0.184 (0.144)	
Epoch: [26][76/76]	Time 0.644 (0.649)	Loss_ce 0.015 (0.051)	Loss_tp 0.031 (0.128)	
Epoch: [27][76/76]	Time 0.576 (0.650)	Loss_ce 0.049 (0.061)	Loss_tp 0.071 (0.146)	
Epoch: [28][76/76]	Time 0.590 (0.656)	Loss_ce 0.006 (0.066)	Loss_tp 0.066 (0.146)	
Epoch: [29][76/76]	Time 0.613 (0.649)	Loss_ce 0.081 (0.089)	Loss_tp 0.062 (0.148)	
Epoch: [30][76/76]	Time 0.586 (0.640)	Loss_ce 0.001 (0.087)	Loss_tp 0.070 (0.147)	
Epoch: [31][76/76]	Time 0.586 (0.645)	Loss_ce 0.004 (0.055)	Loss_tp 0.023 (0.140)	
Epoch: [32][76/76]	Time 1.111 (0.648)	Loss_ce 0.002 (0.054)	Loss_tp 0.085 (0.126)	
Epoch: [33][76/76]	Time 0.570 (0.639)	Loss_ce 0.002 (0.048)	Loss_tp 0.041 (0.121)	
Epoch: [34][76/76]	Time 0.598 (0.646)	Loss_ce 0.017 (0.042)	Loss_tp 0.051 (0.111)	
Epoch: [35][76/76]	Time 0.610 (0.644)	Loss_ce 0.002 (0.050)	Loss_tp 0.091 (0.122)	
Epoch: [36][76/76]	Time 0.955 (0.654)	Loss_ce 0.001 (0.040)	Loss_tp 0.042 (0.110)	
Epoch: [37][76/76]	Time 0.608 (0.641)	Loss_ce 0.004 (0.041)	Loss_tp 0.027 (0.104)	
Epoch: [38][76/76]	Time 0.569 (0.645)	Loss_ce 0.001 (0.043)	Loss_tp 0.072 (0.103)	
Epoch: [39][76/76]	Time 0.602 (0.649)	Loss_ce 0.001 (0.041)	Loss_tp 0.110 (0.104)	
Epoch: [40][76/76]	Time 1.061 (0.653)	Loss_ce 0.001 (0.047)	Loss_tp 0.027 (0.119)	
Epoch: [41][76/76]	Time 0.602 (0.647)	Loss_ce 0.001 (0.044)	Loss_tp 0.036 (0.116)	
Epoch: [42][76/76]	Time 0.611 (0.646)	Loss_ce 0.002 (0.040)	Loss_tp 0.024 (0.108)	
Epoch: [43][76/76]	Time 0.602 (0.652)	Loss_ce 0.001 (0.038)	Loss_tp 0.035 (0.103)	
Epoch: [44][76/76]	Time 0.580 (0.647)	Loss_ce 0.003 (0.036)	Loss_tp 0.053 (0.107)	
Epoch: [45][76/76]	Time 0.606 (0.650)	Loss_ce 0.001 (0.039)	Loss_tp 0.052 (0.113)	
Epoch: [46][76/76]	Time 0.591 (0.656)	Loss_ce 0.001 (0.033)	Loss_tp 0.122 (0.113)	
Epoch: [47][76/76]	Time 0.611 (0.663)	Loss_ce 0.002 (0.041)	Loss_tp 0.010 (0.105)	
Epoch: [48][76/76]	Time 0.593 (0.648)	Loss_ce 0.001 (0.041)	Loss_tp 0.050 (0.093)	
Epoch: [49][76/76]	Time 0.612 (0.658)	Loss_ce 0.003 (0.036)	Loss_tp 0.028 (0.100)	
Epoch: [50][76/76]	Time 0.628 (0.648)	Loss_ce 0.002 (0.034)	Loss_tp 0.040 (0.096)	
Epoch: [51][76/76]	Time 0.590 (0.645)	Loss_ce 0.001 (0.042)	Loss_tp 0.014 (0.104)	
Epoch: [52][76/76]	Time 0.580 (0.646)	Loss_ce 0.004 (0.039)	Loss_tp 0.025 (0.106)	
Epoch: [53][76/76]	Time 0.587 (0.653)	Loss_ce 0.001 (0.033)	Loss_tp 0.040 (0.111)	
Epoch: [54][76/76]	Time 0.575 (0.645)	Loss_ce 0.001 (0.032)	Loss_tp 0.047 (0.096)	
Epoch: [55][76/76]	Time 0.633 (0.638)	Loss_ce 0.023 (0.039)	Loss_tp 0.057 (0.107)	
Epoch: [56][76/76]	Time 0.578 (0.652)	Loss_ce 0.001 (0.034)	Loss_tp 0.077 (0.105)	
Epoch: [57][76/76]	Time 0.566 (0.650)	Loss_ce 0.003 (0.038)	Loss_tp 0.047 (0.100)	
Epoch: [58][76/76]	Time 0.579 (0.657)	Loss_ce 0.001 (0.032)	Loss_tp 0.058 (0.102)	
Epoch: [59][76/76]	Time 0.941 (0.676)	Loss_ce 0.002 (0.037)	Loss_tp 0.023 (0.100)	
=> saved checkpoint '/DATA2025/cjh/AAAI2025-LReID-DASK/output/cuhk03_checkpoint.pth.tar'
****** start perform fast testing! ******
2025-12-15 14:07:08  msmt17 feature start
2025-12-15 14:10:16  msmt17 feature done
fast testing!!!
mAP/Rank1:	23.4/49.9
2025-12-15 14:13:09  cuhk03 feature start
2025-12-15 14:13:19  cuhk03 feature done
fast testing!!!
mAP/Rank1:	42.8/43.6
2025-12-15 14:13:20  sense feature start
2025-12-15 14:13:27  sense feature done
fast testing!!!
mAP/Rank1:	36.1/28.6
2025-12-15 14:13:28  grid feature start
2025-12-15 14:13:30  grid feature done
fast testing!!!
mAP/Rank1:	16.6/9.6
2025-12-15 14:13:30  prid feature start
2025-12-15 14:13:32  prid feature done
fast testing!!!
mAP/Rank1:	35.4/23.0
Average mAP on Seen dataset: 33.1
Average R1 on Seen dataset: 46.7
msmt17		cuhk03		|Average	|
|23.4/49.9	|42.8/43.6	|33.1/46.7	|
Average mAP on UnSeen dataset: 29.3
Average R1 on UnSeen dataset: 20.4
sense	grid	prid	|Average	|
|36.1/28.6	|16.6/9.6	|35.4/23.0	|29.3/20.4	|
33.1	46.7	29.3	20.4
=> saved checkpoint '/DATA2025/cjh/AAAI2025-LReID-DASK/output/cuhk03_checkpoint.pth.tar'
Computing Fisher Information Matrix...
Fisher Matrix Computed on 1024 samples.
*******combining the models with alpha: 0.5*******
module.classifier.weight ...
****** start perform fast testing! ******
2025-12-15 14:13:50  msmt17 feature start
2025-12-15 14:15:33  msmt17 feature done
fast testing!!!
mAP/Rank1:	34.8/61.6
2025-12-15 14:17:38  cuhk03 feature start
2025-12-15 14:17:47  cuhk03 feature done
fast testing!!!
mAP/Rank1:	26.4/25.9
2025-12-15 14:17:47  sense feature start
2025-12-15 14:17:53  sense feature done
fast testing!!!
mAP/Rank1:	38.9/31.0
2025-12-15 14:17:54  grid feature start
2025-12-15 14:17:56  grid feature done
fast testing!!!
mAP/Rank1:	16.1/9.6
2025-12-15 14:17:56  prid feature start
2025-12-15 14:17:58  prid feature done
fast testing!!!
mAP/Rank1:	30.0/20.0
Average mAP on Seen dataset: 30.6
Average R1 on Seen dataset: 43.7
msmt17		cuhk03		|Average	|
|34.8/61.6	|26.4/25.9	|30.6/43.7	|
Average mAP on UnSeen dataset: 28.3
Average R1 on UnSeen dataset: 20.2
sense	grid	prid	|Average	|
|38.9/31.0	|16.1/9.6	|30.0/20.0	|28.3/20.2	|
30.6	43.7	28.3	20.2
Param count for AKPNet's initialized parameters: 1105348
=> Loaded checkpoint 'rehearser_pretrain_learn_kernel_c1-g1_mobilenet-v3/cuhk03_rehearser_49.pth.tar'
Applying Fisher-based Freezing (EWC-style)...
Fisher Threshold: 0.0002262848720420152 (Top 50.0%)
Gradient mask prepared. Approx 12780064 parameters frozen.
using soft triplet loss for training
####### starting training on cuhk_sysu #######
Epoch: [0][34/34]	Time 0.614 (0.656)	Loss_ce 9.393 (9.089)	Loss_tp 0.527 (0.527)	
Epoch: [1][34/34]	Time 0.588 (0.659)	Loss_ce 4.653 (7.108)	Loss_tp 0.512 (0.488)	
Epoch: [2][34/34]	Time 0.586 (0.646)	Loss_ce 0.778 (3.135)	Loss_tp 0.220 (0.342)	
Epoch: [3][34/34]	Time 0.575 (0.656)	Loss_ce 0.205 (0.785)	Loss_tp 0.105 (0.303)	
Epoch: [4][34/34]	Time 0.601 (0.655)	Loss_ce 0.057 (0.321)	Loss_tp 0.016 (0.203)	
Epoch: [5][34/34]	Time 0.616 (0.668)	Loss_ce 0.032 (0.209)	Loss_tp 0.081 (0.194)	
Epoch: [6][34/34]	Time 0.615 (0.650)	Loss_ce 0.046 (0.143)	Loss_tp 0.070 (0.150)	
Epoch: [7][34/34]	Time 0.575 (0.649)	Loss_ce 0.032 (0.138)	Loss_tp 0.087 (0.127)	
Epoch: [8][34/34]	Time 0.592 (0.677)	Loss_ce 0.009 (0.131)	Loss_tp 0.082 (0.118)	
Epoch: [9][34/34]	Time 0.580 (0.657)	Loss_ce 0.011 (0.184)	Loss_tp 0.053 (0.112)	
Epoch: [10][34/34]	Time 0.589 (0.655)	Loss_ce 0.024 (0.204)	Loss_tp 0.085 (0.131)	
Epoch: [11][34/34]	Time 0.684 (0.681)	Loss_ce 0.010 (0.122)	Loss_tp 0.020 (0.115)	
Epoch: [12][34/34]	Time 0.596 (0.663)	Loss_ce 0.005 (0.134)	Loss_tp 0.040 (0.096)	
Epoch: [13][34/34]	Time 0.589 (0.672)	Loss_ce 0.027 (0.101)	Loss_tp 0.121 (0.117)	
Epoch: [14][34/34]	Time 0.617 (0.644)	Loss_ce 0.013 (0.134)	Loss_tp 0.018 (0.091)	
Epoch: [15][34/34]	Time 0.584 (0.673)	Loss_ce 0.012 (0.118)	Loss_tp 0.056 (0.108)	
Epoch: [16][34/34]	Time 0.589 (0.657)	Loss_ce 0.016 (0.075)	Loss_tp 0.062 (0.098)	
Epoch: [17][34/34]	Time 0.628 (0.648)	Loss_ce 0.026 (0.079)	Loss_tp 0.057 (0.090)	
Epoch: [18][34/34]	Time 0.575 (0.675)	Loss_ce 0.404 (0.100)	Loss_tp 0.024 (0.073)	
Epoch: [19][34/34]	Time 0.592 (0.636)	Loss_ce 0.061 (0.085)	Loss_tp 0.021 (0.070)	
Epoch: [20][34/34]	Time 0.608 (0.675)	Loss_ce 0.019 (0.100)	Loss_tp 0.030 (0.082)	
Epoch: [21][34/34]	Time 0.576 (0.660)	Loss_ce 0.002 (0.058)	Loss_tp 0.023 (0.084)	
Epoch: [22][34/34]	Time 0.593 (0.674)	Loss_ce 0.002 (0.078)	Loss_tp 0.042 (0.084)	
Epoch: [23][34/34]	Time 0.593 (0.658)	Loss_ce 0.003 (0.061)	Loss_tp 0.031 (0.080)	
Epoch: [24][34/34]	Time 0.581 (0.659)	Loss_ce 0.004 (0.068)	Loss_tp 0.007 (0.083)	
Epoch: [25][34/34]	Time 0.634 (0.671)	Loss_ce 0.001 (0.040)	Loss_tp 0.032 (0.071)	
Epoch: [26][34/34]	Time 0.586 (0.665)	Loss_ce 0.002 (0.090)	Loss_tp 0.030 (0.086)	
Epoch: [27][34/34]	Time 0.608 (0.652)	Loss_ce 0.214 (0.077)	Loss_tp 0.130 (0.090)	
Epoch: [28][34/34]	Time 0.571 (0.671)	Loss_ce 0.002 (0.078)	Loss_tp 0.029 (0.086)	
Epoch: [29][34/34]	Time 0.579 (0.658)	Loss_ce 0.001 (0.063)	Loss_tp 0.039 (0.081)	
Epoch: [30][34/34]	Time 0.591 (0.669)	Loss_ce 0.007 (0.048)	Loss_tp 0.028 (0.073)	
Epoch: [31][34/34]	Time 0.581 (0.655)	Loss_ce 0.020 (0.026)	Loss_tp 0.053 (0.055)	
Epoch: [32][34/34]	Time 0.937 (0.672)	Loss_ce 0.003 (0.022)	Loss_tp 0.030 (0.068)	
Epoch: [33][34/34]	Time 0.633 (0.657)	Loss_ce 0.002 (0.036)	Loss_tp 0.042 (0.053)	
Epoch: [34][34/34]	Time 0.617 (0.657)	Loss_ce 0.001 (0.034)	Loss_tp 0.027 (0.062)	
Epoch: [35][34/34]	Time 0.571 (0.665)	Loss_ce 0.002 (0.026)	Loss_tp 0.021 (0.058)	
Epoch: [36][34/34]	Time 0.603 (0.661)	Loss_ce 0.001 (0.026)	Loss_tp 0.016 (0.066)	
Epoch: [37][34/34]	Time 0.593 (0.662)	Loss_ce 0.001 (0.029)	Loss_tp 0.016 (0.060)	
Epoch: [38][34/34]	Time 0.598 (0.667)	Loss_ce 0.001 (0.027)	Loss_tp 0.032 (0.054)	
Epoch: [39][34/34]	Time 0.604 (0.681)	Loss_ce 0.002 (0.022)	Loss_tp 0.013 (0.053)	
Epoch: [40][34/34]	Time 0.590 (0.652)	Loss_ce 0.002 (0.028)	Loss_tp 0.016 (0.061)	
Epoch: [41][34/34]	Time 0.589 (0.665)	Loss_ce 0.003 (0.027)	Loss_tp 0.008 (0.057)	
Epoch: [42][34/34]	Time 0.590 (0.671)	Loss_ce 0.004 (0.022)	Loss_tp 0.016 (0.065)	
Epoch: [43][34/34]	Time 0.607 (0.672)	Loss_ce 0.009 (0.021)	Loss_tp 0.010 (0.056)	
Epoch: [44][34/34]	Time 0.586 (0.658)	Loss_ce 0.001 (0.021)	Loss_tp 0.012 (0.063)	
Epoch: [45][34/34]	Time 0.631 (0.656)	Loss_ce 0.002 (0.034)	Loss_tp 0.007 (0.058)	
Epoch: [46][34/34]	Time 0.586 (0.665)	Loss_ce 0.001 (0.032)	Loss_tp 0.006 (0.062)	
Epoch: [47][34/34]	Time 0.580 (0.672)	Loss_ce 0.001 (0.017)	Loss_tp 0.015 (0.059)	
Epoch: [48][34/34]	Time 0.623 (0.675)	Loss_ce 0.019 (0.022)	Loss_tp 0.033 (0.059)	
Epoch: [49][34/34]	Time 0.592 (0.674)	Loss_ce 0.001 (0.024)	Loss_tp 0.027 (0.056)	
Epoch: [50][34/34]	Time 0.586 (0.666)	Loss_ce 0.002 (0.025)	Loss_tp 0.026 (0.053)	
Epoch: [51][34/34]	Time 0.581 (0.678)	Loss_ce 0.003 (0.022)	Loss_tp 0.039 (0.052)	
Epoch: [52][34/34]	Time 0.608 (0.673)	Loss_ce 0.001 (0.022)	Loss_tp 0.021 (0.056)	
Epoch: [53][34/34]	Time 0.587 (0.671)	Loss_ce 0.002 (0.021)	Loss_tp 0.013 (0.062)	
Epoch: [54][34/34]	Time 0.641 (0.672)	Loss_ce 0.001 (0.025)	Loss_tp 0.006 (0.057)	
Epoch: [55][34/34]	Time 0.578 (0.660)	Loss_ce 0.001 (0.026)	Loss_tp 0.030 (0.070)	
Epoch: [56][34/34]	Time 0.629 (0.681)	Loss_ce 0.002 (0.023)	Loss_tp 0.017 (0.077)	
Epoch: [57][34/34]	Time 0.609 (0.687)	Loss_ce 0.001 (0.028)	Loss_tp 0.006 (0.055)	
Epoch: [58][34/34]	Time 0.597 (0.669)	Loss_ce 0.001 (0.015)	Loss_tp 0.006 (0.046)	
Epoch: [59][34/34]	Time 0.580 (0.667)	Loss_ce 0.001 (0.027)	Loss_tp 0.025 (0.061)	
=> saved checkpoint '/DATA2025/cjh/AAAI2025-LReID-DASK/output/cuhk_sysu_checkpoint.pth.tar'
****** start perform fast testing! ******
2025-12-15 14:41:33  msmt17 feature start
2025-12-15 14:43:16  msmt17 feature done
fast testing!!!
mAP/Rank1:	28.7/55.5
2025-12-15 14:45:21  cuhk03 feature start
2025-12-15 14:45:29  cuhk03 feature done
fast testing!!!
mAP/Rank1:	24.9/25.1
2025-12-15 14:45:30  cuhk_sysu feature start
2025-12-15 14:45:39  cuhk_sysu feature done
fast testing!!!
mAP/Rank1:	79.3/81.1
2025-12-15 14:45:41  sense feature start
2025-12-15 14:45:47  sense feature done
fast testing!!!
mAP/Rank1:	40.5/33.0
2025-12-15 14:45:47  grid feature start
2025-12-15 14:45:50  grid feature done
fast testing!!!
mAP/Rank1:	27.0/19.2
2025-12-15 14:45:50  prid feature start
2025-12-15 14:45:52  prid feature done
fast testing!!!
mAP/Rank1:	42.2/33.0
Average mAP on Seen dataset: 44.3
Average R1 on Seen dataset: 53.9
msmt17		cuhk03		cuhk_sysu		|Average	|
|28.7/55.5	|24.9/25.1	|79.3/81.1	|44.3/53.9	|
Average mAP on UnSeen dataset: 36.6
Average R1 on UnSeen dataset: 28.4
sense	grid	prid	|Average	|
|40.5/33.0	|27.0/19.2	|42.2/33.0	|36.6/28.4	|
44.3	53.9	36.6	28.4
=> saved checkpoint '/DATA2025/cjh/AAAI2025-LReID-DASK/output/cuhk_sysu_checkpoint.pth.tar'
Computing Fisher Information Matrix...
Fisher Matrix Computed on 1024 samples.
*******combining the models with alpha: 0.5*******
module.classifier.weight ...
****** start perform fast testing! ******
2025-12-15 14:46:05  msmt17 feature start
2025-12-15 14:47:48  msmt17 feature done
fast testing!!!
mAP/Rank1:	34.6/61.4
2025-12-15 14:49:53  cuhk03 feature start
2025-12-15 14:50:02  cuhk03 feature done
fast testing!!!
mAP/Rank1:	28.0/27.8
2025-12-15 14:50:02  cuhk_sysu feature start
2025-12-15 14:50:12  cuhk_sysu feature done
fast testing!!!
mAP/Rank1:	77.7/80.3
2025-12-15 14:50:14  sense feature start
2025-12-15 14:50:20  sense feature done
fast testing!!!
mAP/Rank1:	41.5/34.3
2025-12-15 14:50:20  grid feature start
2025-12-15 14:50:23  grid feature done
fast testing!!!
mAP/Rank1:	21.3/13.6
2025-12-15 14:50:23  prid feature start
2025-12-15 14:50:25  prid feature done
fast testing!!!
mAP/Rank1:	41.9/33.0
Average mAP on Seen dataset: 46.8
Average R1 on Seen dataset: 56.5
msmt17		cuhk03		cuhk_sysu		|Average	|
|34.6/61.4	|28.0/27.8	|77.7/80.3	|46.8/56.5	|
Average mAP on UnSeen dataset: 34.9
Average R1 on UnSeen dataset: 27.0
sense	grid	prid	|Average	|
|41.5/34.3	|21.3/13.6	|41.9/33.0	|34.9/27.0	|
46.8	56.5	34.9	27.0
Param count for AKPNet's initialized parameters: 1105348
=> Loaded checkpoint 'rehearser_pretrain_learn_kernel_c1-g1_mobilenet-v3/cuhk_sysu_rehearser_49.pth.tar'
Applying Fisher-based Freezing (EWC-style)...
Fisher Threshold: 0.00043051125248894095 (Top 50.0%)
Gradient mask prepared. Approx 13292065 parameters frozen.
using soft triplet loss for training
####### starting training on market1501 #######
Epoch: [0][143/143]	Time 0.587 (0.643)	Loss_ce 8.784 (9.140)	Loss_tp 0.621 (1.005)	
Epoch: [1][143/143]	Time 0.599 (0.646)	Loss_ce 1.893 (3.925)	Loss_tp 1.171 (0.644)	
Epoch: [2][143/143]	Time 0.615 (0.651)	Loss_ce 0.241 (0.847)	Loss_tp 0.531 (0.431)	
Epoch: [3][143/143]	Time 0.573 (0.653)	Loss_ce 0.213 (0.493)	Loss_tp 0.115 (0.365)	
Epoch: [4][143/143]	Time 0.581 (0.647)	Loss_ce 0.150 (0.344)	Loss_tp 0.314 (0.319)	
Epoch: [5][143/143]	Time 0.588 (0.644)	Loss_ce 0.077 (0.289)	Loss_tp 0.115 (0.288)	
Epoch: [6][143/143]	Time 0.604 (0.653)	Loss_ce 0.304 (0.277)	Loss_tp 0.164 (0.258)	
Epoch: [7][143/143]	Time 0.585 (0.650)	Loss_ce 0.070 (0.262)	Loss_tp 0.201 (0.245)	
Epoch: [8][143/143]	Time 0.592 (0.654)	Loss_ce 0.066 (0.302)	Loss_tp 0.275 (0.251)	
Epoch: [9][143/143]	Time 0.592 (0.648)	Loss_ce 0.590 (0.329)	Loss_tp 0.149 (0.269)	
Epoch: [10][143/143]	Time 0.614 (0.651)	Loss_ce 0.218 (0.478)	Loss_tp 0.349 (0.307)	
Epoch: [11][143/143]	Time 0.653 (0.650)	Loss_ce 1.059 (0.434)	Loss_tp 0.315 (0.277)	
Epoch: [12][143/143]	Time 0.600 (0.650)	Loss_ce 0.454 (0.399)	Loss_tp 0.175 (0.314)	
Epoch: [13][143/143]	Time 0.575 (0.650)	Loss_ce 0.159 (0.364)	Loss_tp 0.335 (0.295)	
Epoch: [14][143/143]	Time 0.623 (0.654)	Loss_ce 0.067 (0.342)	Loss_tp 0.170 (0.275)	
Epoch: [15][143/143]	Time 0.599 (0.646)	Loss_ce 0.076 (0.305)	Loss_tp 0.179 (0.277)	
Epoch: [16][143/143]	Time 0.590 (0.647)	Loss_ce 0.157 (0.260)	Loss_tp 0.401 (0.273)	
Epoch: [17][143/143]	Time 0.592 (0.649)	Loss_ce 0.127 (0.263)	Loss_tp 0.331 (0.255)	
Epoch: [18][143/143]	Time 0.580 (0.654)	Loss_ce 0.067 (0.249)	Loss_tp 0.139 (0.259)	
Epoch: [19][143/143]	Time 0.623 (0.657)	Loss_ce 0.021 (0.262)	Loss_tp 0.324 (0.251)	
Epoch: [20][143/143]	Time 0.605 (0.653)	Loss_ce 0.108 (0.252)	Loss_tp 0.115 (0.274)	
Epoch: [21][143/143]	Time 0.595 (0.665)	Loss_ce 0.274 (0.279)	Loss_tp 0.137 (0.270)	
Epoch: [22][143/143]	Time 0.591 (0.655)	Loss_ce 0.313 (0.306)	Loss_tp 0.285 (0.287)	
Epoch: [23][143/143]	Time 0.606 (0.657)	Loss_ce 0.328 (0.289)	Loss_tp 0.138 (0.299)	
Epoch: [24][143/143]	Time 0.592 (0.658)	Loss_ce 0.002 (0.227)	Loss_tp 0.177 (0.273)	
Epoch: [25][143/143]	Time 0.599 (0.655)	Loss_ce 0.128 (0.259)	Loss_tp 0.177 (0.270)	
Epoch: [26][143/143]	Time 0.605 (0.660)	Loss_ce 0.006 (0.229)	Loss_tp 0.329 (0.287)	
Epoch: [27][143/143]	Time 0.579 (0.653)	Loss_ce 0.006 (0.208)	Loss_tp 0.165 (0.252)	
Epoch: [28][143/143]	Time 0.583 (0.650)	Loss_ce 0.054 (0.227)	Loss_tp 0.436 (0.260)	
Epoch: [29][143/143]	Time 0.578 (0.649)	Loss_ce 0.250 (0.270)	Loss_tp 0.193 (0.312)	
Epoch: [30][143/143]	Time 0.581 (0.649)	Loss_ce 0.039 (0.174)	Loss_tp 0.125 (0.262)	
Epoch: [31][143/143]	Time 0.591 (0.652)	Loss_ce 0.004 (0.125)	Loss_tp 0.236 (0.217)	
Epoch: [32][143/143]	Time 0.593 (0.652)	Loss_ce 0.137 (0.116)	Loss_tp 0.089 (0.210)	
Epoch: [33][143/143]	Time 0.603 (0.655)	Loss_ce 0.002 (0.097)	Loss_tp 0.140 (0.189)	
Epoch: [34][143/143]	Time 0.622 (0.657)	Loss_ce 0.009 (0.100)	Loss_tp 0.074 (0.185)	
Epoch: [35][143/143]	Time 0.617 (0.660)	Loss_ce 0.008 (0.081)	Loss_tp 0.053 (0.184)	
Epoch: [36][143/143]	Time 0.594 (0.661)	Loss_ce 0.007 (0.085)	Loss_tp 0.042 (0.175)	
Epoch: [37][143/143]	Time 0.601 (0.655)	Loss_ce 0.003 (0.077)	Loss_tp 0.080 (0.175)	
Epoch: [38][143/143]	Time 0.585 (0.647)	Loss_ce 0.000 (0.081)	Loss_tp 0.120 (0.175)	
Epoch: [39][143/143]	Time 0.593 (0.651)	Loss_ce 0.000 (0.082)	Loss_tp 0.035 (0.172)	
Epoch: [40][143/143]	Time 0.616 (0.655)	Loss_ce 0.001 (0.071)	Loss_tp 0.038 (0.157)	
Epoch: [41][143/143]	Time 0.593 (0.656)	Loss_ce 0.000 (0.074)	Loss_tp 0.076 (0.160)	
Epoch: [42][143/143]	Time 0.615 (0.648)	Loss_ce 0.002 (0.067)	Loss_tp 0.042 (0.158)	
Epoch: [43][143/143]	Time 0.579 (0.657)	Loss_ce 0.038 (0.068)	Loss_tp 0.069 (0.155)	
Epoch: [44][143/143]	Time 0.594 (0.653)	Loss_ce 0.009 (0.064)	Loss_tp 0.024 (0.162)	
Epoch: [45][143/143]	Time 0.584 (0.646)	Loss_ce 0.072 (0.068)	Loss_tp 0.216 (0.169)	
Epoch: [46][143/143]	Time 0.962 (0.651)	Loss_ce 0.001 (0.057)	Loss_tp 0.118 (0.147)	
Epoch: [47][143/143]	Time 0.633 (0.652)	Loss_ce 0.005 (0.062)	Loss_tp 0.030 (0.156)	
Epoch: [48][143/143]	Time 0.611 (0.661)	Loss_ce 0.026 (0.062)	Loss_tp 0.307 (0.157)	
Epoch: [49][143/143]	Time 0.592 (0.651)	Loss_ce 0.001 (0.061)	Loss_tp 0.042 (0.150)	
Epoch: [50][143/143]	Time 0.574 (0.644)	Loss_ce 0.004 (0.065)	Loss_tp 0.065 (0.155)	
Epoch: [51][143/143]	Time 0.642 (0.648)	Loss_ce 0.001 (0.058)	Loss_tp 0.097 (0.141)	
Epoch: [52][143/143]	Time 0.588 (0.652)	Loss_ce 0.000 (0.052)	Loss_tp 0.043 (0.153)	
Epoch: [53][143/143]	Time 0.574 (0.649)	Loss_ce 0.001 (0.053)	Loss_tp 0.016 (0.151)	
Epoch: [54][143/143]	Time 0.576 (0.654)	Loss_ce 0.000 (0.062)	Loss_tp 0.039 (0.146)	
Epoch: [55][143/143]	Time 0.665 (0.655)	Loss_ce 0.000 (0.063)	Loss_tp 0.065 (0.151)	
Epoch: [56][143/143]	Time 0.608 (0.650)	Loss_ce 0.002 (0.054)	Loss_tp 0.096 (0.146)	
Epoch: [57][143/143]	Time 0.579 (0.655)	Loss_ce 0.000 (0.064)	Loss_tp 0.047 (0.155)	
Epoch: [58][143/143]	Time 0.603 (0.654)	Loss_ce 0.001 (0.057)	Loss_tp 0.025 (0.151)	
Epoch: [59][143/143]	Time 0.594 (0.650)	Loss_ce 0.013 (0.053)	Loss_tp 0.060 (0.146)	
=> saved checkpoint '/DATA2025/cjh/AAAI2025-LReID-DASK/output/market1501_checkpoint.pth.tar'
****** start perform fast testing! ******
2025-12-15 16:24:47  msmt17 feature start
2025-12-15 16:26:31  msmt17 feature done
fast testing!!!
mAP/Rank1:	23.4/49.9
2025-12-15 16:28:34  cuhk03 feature start
2025-12-15 16:28:42  cuhk03 feature done
fast testing!!!
mAP/Rank1:	22.7/23.0
2025-12-15 16:28:43  cuhk_sysu feature start
2025-12-15 16:28:53  cuhk_sysu feature done
fast testing!!!
mAP/Rank1:	78.5/81.4
2025-12-15 16:28:55  market1501 feature start
2025-12-15 16:29:15  market1501 feature done
fast testing!!!
mAP/Rank1:	67.9/85.8
2025-12-15 16:29:22  sense feature start
2025-12-15 16:29:27  sense feature done
fast testing!!!
mAP/Rank1:	42.1/34.0
2025-12-15 16:29:28  grid feature start
2025-12-15 16:29:30  grid feature done
fast testing!!!
mAP/Rank1:	32.2/24.0
2025-12-15 16:29:30  prid feature start
2025-12-15 16:29:32  prid feature done
fast testing!!!
mAP/Rank1:	47.0/36.0
Average mAP on Seen dataset: 48.1
Average R1 on Seen dataset: 60.0
msmt17		cuhk03		cuhk_sysu		market1501		|Average	|
|23.4/49.9	|22.7/23.0	|78.5/81.4	|67.9/85.8	|48.1/60.0	|
Average mAP on UnSeen dataset: 40.4
Average R1 on UnSeen dataset: 31.3
sense	grid	prid	|Average	|
|42.1/34.0	|32.2/24.0	|47.0/36.0	|40.4/31.3	|
48.1	60.0	40.4	31.3
=> saved checkpoint '/DATA2025/cjh/AAAI2025-LReID-DASK/output/market1501_checkpoint.pth.tar'
Computing Fisher Information Matrix...
Fisher Matrix Computed on 1024 samples.
*******combining the models with alpha: 0.5*******
module.classifier.weight ...
****** start perform fast testing! ******
2025-12-15 16:29:55  msmt17 feature start
2025-12-15 16:31:36  msmt17 feature done
fast testing!!!
mAP/Rank1:	32.3/59.2
2025-12-15 16:33:41  cuhk03 feature start
2025-12-15 16:33:50  cuhk03 feature done
fast testing!!!
mAP/Rank1:	29.1/28.7
2025-12-15 16:33:50  cuhk_sysu feature start
2025-12-15 16:34:01  cuhk_sysu feature done
fast testing!!!
mAP/Rank1:	79.6/81.8
2025-12-15 16:34:02  market1501 feature start
2025-12-15 16:34:22  market1501 feature done
fast testing!!!
mAP/Rank1:	54.0/76.6
2025-12-15 16:34:28  sense feature start
2025-12-15 16:34:34  sense feature done
fast testing!!!
mAP/Rank1:	44.3/36.4
2025-12-15 16:34:35  grid feature start
2025-12-15 16:34:37  grid feature done
fast testing!!!
mAP/Rank1:	27.8/20.0
2025-12-15 16:34:37  prid feature start
2025-12-15 16:34:39  prid feature done
fast testing!!!
mAP/Rank1:	45.7/38.0
Average mAP on Seen dataset: 48.8
Average R1 on Seen dataset: 61.6
msmt17		cuhk03		cuhk_sysu		market1501		|Average	|
|32.3/59.2	|29.1/28.7	|79.6/81.8	|54.0/76.6	|48.8/61.6	|
Average mAP on UnSeen dataset: 39.2
Average R1 on UnSeen dataset: 31.5
sense	grid	prid	|Average	|
|44.3/36.4	|27.8/20.0	|45.7/38.0	|39.2/31.5	|
48.8	61.6	39.2	31.5
Param count for AKPNet's initialized parameters: 1105348
=> Loaded checkpoint 'rehearser_pretrain_learn_kernel_c1-g1_mobilenet-v3/market1501_rehearser_49.pth.tar'
Applying Fisher-based Freezing (EWC-style)...
Fisher Threshold: 0.0007835139986127615 (Top 50.0%)
Gradient mask prepared. Approx 13804064 parameters frozen.
using soft triplet loss for training
####### starting training on dukemtmc #######
Epoch: [0][172/172]	Time 0.660 (0.660)	Loss_ce 12.892 (15.319)	Loss_tp 0.756 (1.168)	
Epoch: [1][172/172]	Time 0.587 (0.658)	Loss_ce 2.341 (6.386)	Loss_tp 0.846 (0.819)	
Epoch: [2][172/172]	Time 0.617 (0.659)	Loss_ce 0.519 (1.147)	Loss_tp 0.307 (0.586)	
Epoch: [3][172/172]	Time 0.594 (0.653)	Loss_ce 0.274 (0.600)	Loss_tp 0.239 (0.471)	
Epoch: [4][172/172]	Time 0.586 (0.654)	Loss_ce 0.135 (0.402)	Loss_tp 0.226 (0.400)	
Epoch: [5][172/172]	Time 0.599 (0.655)	Loss_ce 0.128 (0.339)	Loss_tp 0.299 (0.378)	
Epoch: [6][172/172]	Time 0.603 (0.660)	Loss_ce 0.071 (0.302)	Loss_tp 0.269 (0.356)	
Epoch: [7][172/172]	Time 0.585 (0.665)	Loss_ce 0.128 (0.271)	Loss_tp 0.259 (0.344)	
Epoch: [8][172/172]	Time 0.589 (0.664)	Loss_ce 0.134 (0.242)	Loss_tp 0.235 (0.318)	
Epoch: [9][172/172]	Time 0.600 (0.658)	Loss_ce 0.221 (0.245)	Loss_tp 0.323 (0.327)	
Epoch: [10][172/172]	Time 0.598 (0.654)	Loss_ce 0.629 (0.298)	Loss_tp 0.143 (0.344)	
Epoch: [11][172/172]	Time 0.588 (0.660)	Loss_ce 0.043 (0.282)	Loss_tp 0.136 (0.335)	
Epoch: [12][172/172]	Time 0.612 (0.657)	Loss_ce 0.168 (0.256)	Loss_tp 0.219 (0.348)	
Epoch: [13][172/172]	Time 0.623 (0.657)	Loss_ce 0.065 (0.246)	Loss_tp 0.203 (0.330)	
Epoch: [14][172/172]	Time 0.626 (0.655)	Loss_ce 0.007 (0.221)	Loss_tp 0.186 (0.325)	
Epoch: [15][172/172]	Time 0.609 (0.653)	Loss_ce 0.176 (0.203)	Loss_tp 0.318 (0.337)	
Epoch: [16][172/172]	Time 0.596 (0.660)	Loss_ce 1.126 (0.268)	Loss_tp 0.319 (0.367)	
Epoch: [17][172/172]	Time 0.600 (0.657)	Loss_ce 0.089 (0.213)	Loss_tp 0.151 (0.344)	
Epoch: [18][172/172]	Time 0.633 (0.658)	Loss_ce 0.091 (0.213)	Loss_tp 0.181 (0.314)	
Epoch: [19][172/172]	Time 0.592 (0.655)	Loss_ce 0.001 (0.174)	Loss_tp 0.190 (0.309)	
Epoch: [20][172/172]	Time 0.602 (0.658)	Loss_ce 0.138 (0.177)	Loss_tp 0.259 (0.312)	
Epoch: [21][172/172]	Time 0.596 (0.660)	Loss_ce 0.008 (0.192)	Loss_tp 0.109 (0.310)	
Epoch: [22][172/172]	Time 0.596 (0.660)	Loss_ce 0.018 (0.179)	Loss_tp 0.317 (0.319)	
Epoch: [23][172/172]	Time 0.637 (0.660)	Loss_ce 0.051 (0.153)	Loss_tp 0.357 (0.308)	
Epoch: [24][172/172]	Time 0.595 (0.659)	Loss_ce 0.028 (0.152)	Loss_tp 0.236 (0.295)	
Epoch: [25][172/172]	Time 0.777 (0.703)	Loss_ce 0.235 (0.188)	Loss_tp 0.176 (0.336)	
Epoch: [26][172/172]	Time 0.653 (0.876)	Loss_ce 0.216 (0.211)	Loss_tp 0.490 (0.360)	
Epoch: [27][172/172]	Time 0.763 (0.855)	Loss_ce 0.005 (0.157)	Loss_tp 0.352 (0.322)	
Epoch: [28][172/172]	Time 0.585 (0.706)	Loss_ce 0.012 (0.148)	Loss_tp 0.229 (0.306)	
Epoch: [29][172/172]	Time 0.593 (0.660)	Loss_ce 0.020 (0.159)	Loss_tp 0.227 (0.320)	
Epoch: [30][172/172]	Time 0.903 (0.806)	Loss_ce 0.170 (0.142)	Loss_tp 0.176 (0.287)	
Epoch: [31][172/172]	Time 0.777 (0.846)	Loss_ce 0.007 (0.102)	Loss_tp 0.245 (0.258)	
Epoch: [32][172/172]	Time 0.619 (0.761)	Loss_ce 0.003 (0.095)	Loss_tp 0.064 (0.242)	
Epoch: [33][172/172]	Time 0.598 (0.664)	Loss_ce 0.017 (0.091)	Loss_tp 0.194 (0.228)	
Epoch: [34][172/172]	Time 0.606 (0.667)	Loss_ce 0.001 (0.086)	Loss_tp 0.100 (0.217)	
Epoch: [35][172/172]	Time 0.640 (0.667)	Loss_ce 0.002 (0.080)	Loss_tp 0.118 (0.220)	
Epoch: [36][172/172]	Time 0.609 (0.685)	Loss_ce 0.004 (0.085)	Loss_tp 0.200 (0.213)	
Epoch: [37][172/172]	Time 0.621 (0.671)	Loss_ce 0.000 (0.080)	Loss_tp 0.198 (0.210)	
Epoch: [38][172/172]	Time 0.600 (0.665)	Loss_ce 0.001 (0.076)	Loss_tp 0.035 (0.198)	
Epoch: [39][172/172]	Time 0.648 (0.676)	Loss_ce 0.000 (0.073)	Loss_tp 0.113 (0.194)	
Epoch: [40][172/172]	Time 0.640 (0.687)	Loss_ce 0.000 (0.075)	Loss_tp 0.213 (0.202)	
Epoch: [41][172/172]	Time 0.609 (0.698)	Loss_ce 0.028 (0.073)	Loss_tp 0.422 (0.205)	
Epoch: [42][172/172]	Time 0.632 (0.682)	Loss_ce 0.002 (0.073)	Loss_tp 0.089 (0.193)	
Epoch: [43][172/172]	Time 0.622 (0.677)	Loss_ce 0.001 (0.070)	Loss_tp 0.209 (0.198)	
Epoch: [44][172/172]	Time 0.667 (0.676)	Loss_ce 0.001 (0.069)	Loss_tp 0.080 (0.186)	
Epoch: [45][172/172]	Time 0.619 (0.674)	Loss_ce 0.000 (0.065)	Loss_tp 0.156 (0.198)	
Epoch: [46][172/172]	Time 0.609 (0.673)	Loss_ce 0.002 (0.068)	Loss_tp 0.157 (0.191)	
Epoch: [47][172/172]	Time 0.595 (0.675)	Loss_ce 0.002 (0.068)	Loss_tp 0.081 (0.185)	
Epoch: [48][172/172]	Time 0.662 (0.677)	Loss_ce 0.000 (0.066)	Loss_tp 0.230 (0.196)	
Epoch: [49][172/172]	Time 0.867 (0.848)	Loss_ce 0.001 (0.066)	Loss_tp 0.130 (0.185)	
Epoch: [50][172/172]	Time 0.615 (0.872)	Loss_ce 0.003 (0.069)	Loss_tp 0.044 (0.190)	
Epoch: [51][172/172]	Time 0.769 (0.867)	Loss_ce 0.005 (0.064)	Loss_tp 0.087 (0.175)	
Epoch: [52][172/172]	Time 0.743 (0.864)	Loss_ce 0.003 (0.069)	Loss_tp 0.054 (0.189)	
Epoch: [53][172/172]	Time 0.831 (0.892)	Loss_ce 0.000 (0.062)	Loss_tp 0.102 (0.186)	
Epoch: [54][172/172]	Time 0.678 (0.875)	Loss_ce 0.001 (0.066)	Loss_tp 0.041 (0.191)	
Epoch: [55][172/172]	Time 0.705 (0.870)	Loss_ce 0.000 (0.058)	Loss_tp 0.061 (0.176)	
Epoch: [56][172/172]	Time 0.768 (0.858)	Loss_ce 0.002 (0.066)	Loss_tp 0.284 (0.181)	
Epoch: [57][172/172]	Time 0.696 (0.895)	Loss_ce 0.000 (0.063)	Loss_tp 0.086 (0.185)	
Epoch: [58][172/172]	Time 0.754 (0.887)	Loss_ce 0.001 (0.069)	Loss_tp 0.055 (0.187)	
Epoch: [59][172/172]	Time 0.669 (0.901)	Loss_ce 0.059 (0.063)	Loss_tp 0.082 (0.186)	
=> saved checkpoint '/DATA2025/cjh/AAAI2025-LReID-DASK/output/dukemtmc_checkpoint.pth.tar'
****** start perform fast testing! ******
2025-12-15 18:39:36  msmt17 feature start
2025-12-15 18:51:36  msmt17 feature done
fast testing!!!
mAP/Rank1:	22.9/49.7
2025-12-15 20:17:40  cuhk03 feature start
2025-12-15 20:19:30  cuhk03 feature done
fast testing!!!
mAP/Rank1:	21.0/21.3
2025-12-15 20:19:31  cuhk_sysu feature start
2025-12-15 20:20:05  cuhk_sysu feature done
fast testing!!!
mAP/Rank1:	74.4/77.6
2025-12-15 20:20:07  market1501 feature start
2025-12-15 20:21:19  market1501 feature done
fast testing!!!
mAP/Rank1:	43.8/70.9
2025-12-15 20:21:27  dukemtmc feature start
2025-12-15 20:22:51  dukemtmc feature done
fast testing!!!
mAP/Rank1:	61.0/77.5
2025-12-15 20:22:56  sense feature start
2025-12-15 20:23:16  sense feature done
fast testing!!!
mAP/Rank1:	37.7/30.5
2025-12-15 20:23:16  grid feature start
2025-12-15 20:23:23  grid feature done
fast testing!!!
mAP/Rank1:	32.1/23.2
2025-12-15 20:23:23  prid feature start
2025-12-15 20:23:28  prid feature done
fast testing!!!
mAP/Rank1:	48.9/37.0
Average mAP on Seen dataset: 44.6
Average R1 on Seen dataset: 59.4
msmt17		cuhk03		cuhk_sysu		market1501		dukemtmc		|Average	|
|22.9/49.7	|21.0/21.3	|74.4/77.6	|43.8/70.9	|61.0/77.5	|44.6/59.4	|
Average mAP on UnSeen dataset: 39.6
Average R1 on UnSeen dataset: 30.2
sense	grid	prid	|Average	|
|37.7/30.5	|32.1/23.2	|48.9/37.0	|39.6/30.2	|
44.6	59.4	39.6	30.2
=> saved checkpoint '/DATA2025/cjh/AAAI2025-LReID-DASK/output/dukemtmc_checkpoint.pth.tar'
Computing Fisher Information Matrix...
Fisher Matrix Computed on 1024 samples.
*******combining the models with alpha: 0.5*******
module.classifier.weight ...
****** start perform fast testing! ******
2025-12-15 20:24:23  msmt17 feature start
2025-12-15 20:38:58  msmt17 feature done
fast testing!!!
mAP/Rank1:	31.2/58.1
2025-12-15 21:07:45  cuhk03 feature start
2025-12-15 21:11:32  cuhk03 feature done
fast testing!!!
mAP/Rank1:	28.0/28.3
2025-12-15 21:11:33  cuhk_sysu feature start
2025-12-15 21:12:27  cuhk_sysu feature done
fast testing!!!
mAP/Rank1:	79.3/81.9
2025-12-15 21:12:29  market1501 feature start
2025-12-15 21:13:48  market1501 feature done
fast testing!!!
mAP/Rank1:	53.8/76.6
2025-12-15 21:13:54  dukemtmc feature start
2025-12-15 21:15:46  dukemtmc feature done
fast testing!!!
mAP/Rank1:	53.2/71.3
2025-12-15 21:15:51  sense feature start
2025-12-15 21:16:16  sense feature done
fast testing!!!
mAP/Rank1:	43.6/35.4
2025-12-15 21:16:16  grid feature start
2025-12-15 21:16:20  grid feature done
fast testing!!!
mAP/Rank1:	31.2/20.8
2025-12-15 21:16:20  prid feature start
2025-12-15 21:16:24  prid feature done
fast testing!!!
mAP/Rank1:	48.7/41.0
Average mAP on Seen dataset: 49.1
Average R1 on Seen dataset: 63.2
msmt17		cuhk03		cuhk_sysu		market1501		dukemtmc		|Average	|
|31.2/58.1	|28.0/28.3	|79.3/81.9	|53.8/76.6	|53.2/71.3	|49.1/63.2	|
Average mAP on UnSeen dataset: 41.1
Average R1 on UnSeen dataset: 32.4
sense	grid	prid	|Average	|
|43.6/35.4	|31.2/20.8	|48.7/41.0	|41.1/32.4	|
49.1	63.2	41.1	32.4
finished